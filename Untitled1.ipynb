{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, num_neurons, output_weights=None):\n",
    "        self.num_neurons = num_neurons\n",
    "        self.bias = [np.random.rand(y,1) for y in num_neurons[1:]]\n",
    "        self.weights = [np.random.rand(y,x) for x,y in zip(num_neurons[:-1], num_neurons[1:])]\n",
    "    def propForward(self, inputs):\n",
    "        for b, w in zip(self.bias, self.weights):\n",
    "            print(inputs)\n",
    "            inputs=1./(1.+np.exp(-w.dot(inputs)-b))\n",
    "            print(inputs)\n",
    "    def training(self, inputs, eta):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.bias]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        delta_nabla_b, delta_nabla_w = #Back Propagation\n",
    "        \n",
    "        nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        \n",
    "        self.weights = [w-(eta)*nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.bias = [b-(eta)*nb for b, nb in zip(self.bias, nabla_b)]\n",
    "    def backProp(self, inputs,answer):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.bias]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[[ 0.76904192  0.83533665  0.72305925  0.72981125]\n",
      " [ 0.76189571  0.82978769  0.71501749  0.72189015]\n",
      " [ 0.79815842  0.85764256  0.75613447  0.76234512]\n",
      " [ 0.68926645  0.7716611   0.63494038  0.64277938]]\n",
      "[[ 0.76904192  0.83533665  0.72305925  0.72981125]\n",
      " [ 0.76189571  0.82978769  0.71501749  0.72189015]\n",
      " [ 0.79815842  0.85764256  0.75613447  0.76234512]\n",
      " [ 0.68926645  0.7716611   0.63494038  0.64277938]]\n",
      "[[ 0.90464751  0.91477341  0.89699352  0.89815126]\n",
      " [ 0.92395113  0.93350586  0.91661707  0.91773223]\n",
      " [ 0.85035379  0.86222956  0.84184867  0.84311113]\n",
      " [ 0.93945282  0.94881927  0.93207337  0.93320537]\n",
      " [ 0.93926454  0.94803486  0.93240931  0.93345816]\n",
      " [ 0.74338331  0.75892489  0.73252333  0.73412163]\n",
      " [ 0.80028809  0.82000571  0.78604299  0.78816289]\n",
      " [ 0.85172071  0.86828695  0.83947765  0.84131412]\n",
      " [ 0.69918257  0.71165091  0.69049565  0.69177333]\n",
      " [ 0.88104753  0.89836111  0.86787094  0.86986677]]\n"
     ]
    }
   ],
   "source": [
    "n1 = Network([2,4, 10])\n",
    "n1.propForward([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
